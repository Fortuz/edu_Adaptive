{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"assets/logo.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Made by **Balázs Nagy** and **Márk Domokos**\n",
    "\n",
    "[<img src=\"assets/open_button.png\">](https://colab.research.google.com/github/Fortuz/edu_Adaptive/blob/main/practices/L02%20-%20Multivariate%20Linear%20Regression_solved.ipynb)\n",
    "\n",
    "# Labor 02: Multivariate linear regression\n",
    "\n",
    "### Property prices:\n",
    "\n",
    "In this exercise, we will extend our univariate linear regression model introduced in lab L01 to the multivariate linear regression case to estimate house prices.\n",
    "\n",
    "Suppose we want to sell a house, but we want to know the real value of the house so that we do not lose money on the sale. One possible way to do this is to collect data and then estimate the real estate market price of the house by building a model based on the data. Our data will be the area of the property ($m^2$) and the number of rooms (units), and the price ($) determined at the time of sale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1: Import the packages\n",
    "We will need:\n",
    "- NumPy for array management\n",
    "- MatPlotLib pyplot package for visualization\n",
    "- Pandas for data reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2: Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data will be loaded from a publicly available file. An alternative solution would be to upload the data file directly to the google colab file system. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://github.com/Fortuz/edu_Adaptive/raw/main/practices/assets/Lab02/Lab2data.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in the data! Use the Pandas package to do this and then convert it into a numpy array. Visualize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Lab2data.txt',header = None).to_numpy()   \n",
    "X = data[:,0:2]                                                # sort X\n",
    "m = X.shape[0]                                                 # number of samples\n",
    "Y = data[:,2].reshape(m,1)                                     # sort Y\n",
    "\n",
    "print('X:',X.shape)                                            # check the shapes\n",
    "print('Y:',Y.shape)\n",
    "print('Number of samples: ',m)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3: Normalising values (Feature scaling & Mean normalization)\n",
    "\n",
    "The features of the data points may be in different magnitudes. In our case, it is easy to see that there is at least an order of magnitude difference between the area of the property and the number of rooms. In such cases, it is worth normalising our values so that they fall within the same order of magnitude and all input variables fall within the range of [-1..1] or [0..1] interval. This operation will promote convergence, as there will be no dominant variable present to suppress the effect of other variables. <br>\n",
    "For this we will use the following relationship:\n",
    "\n",
    "$ x = \\frac{x - mean(x)}{std(x)} $\n",
    "\n",
    ", with other words the mean of the samples is subtracted from a given sample (mean normalization) and divided by the standard deviation of the samples (feature scaling).\n",
    "\n",
    "Graphical meaning: around the origin makes it easier to find the line that covers our data according to our hypothesis. It is therefore useful to trasform our data into this region."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"assets/Lab02/Pics/L02_Scaling.png\" width=\"350\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the normalizing function!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureNormalize(X):\n",
    "################### CODE HERE ########################   \n",
    "# Calculate the normalized X vector.\n",
    "# To do so calculate the mean and standard deviation of the input data first.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "######################################################\n",
    "    return X_norm, avg, sigma                            # return the formula based result \n",
    "\n",
    "print('Normalizing X vector ...')                       \n",
    "X_norm,avg,sigma = featureNormalize(X)                   # normalization\n",
    "X_norm=np.column_stack((np.ones(m),X_norm))              # add bias\n",
    "print('Normalization done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After normalization, the BIAS is added to the input X matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4: Gradient based method\n",
    "Following the example of the previous exercise, we create the gradient method in multivariable form! Our data structure is as follows.\n",
    "\n",
    "<img src=\"assets/Lab02/Pics/L02_Matrixok.png\" width=\"500\">\n",
    "\n",
    "Here we have more features so the input vector is bigger, but everything will work as previously."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hypothesis function for the multivariate case can be written as follows:\n",
    "\n",
    "$ h_{w}(x)=w_0x_0+w_1x_1+w_2x_2+ ... +w_nx_n $ <br>\n",
    "\n",
    "And with matrix operations:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"assets/Lab02/Pics/L02_XW.png\" width=\"550\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formula of the cost function: <br>\n",
    "\n",
    "$ C(W)=C(w_0,w_1,...,w_n)=\\frac{1}{2m}\\sum_{i=1}^{m}(h_w(x^i)-y^i)^2 $\n",
    "\n",
    "Tip: When programming, take advantage of vector multiplication.\n",
    "\n",
    "<img src=\"assets/Lab02/Pics/L02_Sum.png\" width=\"550\">\n",
    "\n",
    "General weight update formula of the gradient method:\n",
    "\n",
    "$ \\color{red}{(j=0...n)}\\hspace{7mm} w_j:=w_j-\\mu\\frac{1}{2m}\\sum_{i=1}^{m}((h_w(x^i)-y^i)\\cdot x_j^i) $\n",
    "\n",
    "$\\color{red}{Pay\\ attention\\ to\\ the\\ simultaneous\\ update!}$\n",
    "\n",
    "Current matrix values are used to calculate the new updated matrix values. If a calculated value stored back in the matrix and this already updated value is used to calculate the next updated value in the same matrix it will result in a faulty calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cost function\n",
    "def computeCostMulti(X,Y,W):\n",
    "    C=0   # To make sure there is nothing in this variable\n",
    "\n",
    "    ################### CODE HERE ########################     \n",
    "    # Implement the cost function\n",
    " \n",
    " \n",
    "    #####################################################\n",
    "\n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient descent Method\n",
    "def gradientDescentMulti(X,Y,W,lr,epochs):            \n",
    "      \n",
    "    ################### CODE HERE ######################## \n",
    "    # Implement the Gradient Descent algorithm for multiple variables    \n",
    "    \n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "   \n",
    "    #####################################################\n",
    "\n",
    "    return W, C_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try out the Gradient Descent algorithm with multiple variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Running gradient descent ...')\n",
    "lr = 0.015                                                  # learning rate\n",
    "epochs = 1200                                               # number of epochs\n",
    "W=np.zeros((3,1))                                           # initial weights (0;0;0)\n",
    "W,C_history= gradientDescentMulti(X_norm,Y,W,lr,epochs)     # Use the Gradient Descent Method\n",
    "print('''Weights expected from gradient descent (approx.):\n",
    " [[340372.05039403]\n",
    " [109434.51046856]\n",
    " [ -5454.97874429 ]]\n",
    "''')\n",
    "print('Weights computed from gradient descent:\\n', W)\n",
    "\n",
    "if int(W[0,0]) == 340372 and int(W[1,0]) == 109434 and int(W[2,0]) == -5454:\n",
    "    print(\"\\n The gradientDescentMulti() function is good. You can proceed.\")\n",
    "else:\n",
    "    print(\"\\n Something not right. Please modify the function!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the convergence with the help of a graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(C_history)                                                                 # C_history plot\n",
    "plt.title(\"Gradient descent algorithm's effect through the iterations\",pad= 20)\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Cost function value\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5: Prediction\n",
    "Let's estimate the price of a 1650 $m^2$, 3 bedroom property! Watch for the normalization of the data, which is also neccessary here. Use the previously calculated mean and sigma for the normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(FEET, BED):\n",
    "\n",
    "    ################### CODE HERE ########################    \n",
    "    # Predict the prize of a house given by the size (FEET) and number of bedrooms (BED)\n",
    "     \n",
    "   \n",
    "    \n",
    "    #####################################################\n",
    "\n",
    "    return price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEET = 1650\n",
    "BED = 3\n",
    "price = predict(FEET, BED)\n",
    "print('''Prediction for a 1650 sq-ft / 3 bedroom house:\n",
    "(predicted price should be approx. $293000) %.2f''' % price[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In a slightly different way: with high level packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "data = pd.read_csv('Lab2data.txt',header = None)   \n",
    "\n",
    "X = data.iloc[:, 0:2].values.reshape(-1,2)                              # arrange X\n",
    "Y = data.iloc[:, 2].values.reshape(-1,1)                                # arrange Y \n",
    "\n",
    "lin_reg = LinearRegression()                                            # creation of a linear regression model class\n",
    "lin_reg.fit(X,Y)                                                        # fit based on X,Y\n",
    "\n",
    "pred = lin_reg.predict([[1650,3]])                                      # prediction for a house with 1650 m^2 and 3 bedrooms\n",
    "print('Prediction for a 1650 sq-ft / 3 bedroom house:\\n %.2f' % pred[0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\">This lab exercise uses elements from Andrew Ng's Machine Learning course.</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
